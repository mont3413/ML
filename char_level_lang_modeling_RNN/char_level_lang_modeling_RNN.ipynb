{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ef331e-4e87-483f-a473-340b8063d8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length: 1112310\n",
      "Unique characters: 80\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "with open('1268-0.txt') as fp: # THE MYSTERIOUS ISLAND by Jules Verne\n",
    "    text = fp.read()\n",
    "\n",
    "start_idx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_idx = text.find('End of the Project Gutenberg')\n",
    "text = text[start_idx:end_idx]\n",
    "char_set = set(text)\n",
    "print(f'Text length: {len(text)}')\n",
    "print(f'Unique characters: {len(char_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e47857-e9f5-4614-989b-b4a5b5de5d9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'char_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chars_sorted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mchar_set\u001b[49m)\n\u001b[1;32m      2\u001b[0m char2int \u001b[38;5;241m=\u001b[39m {ch:i \u001b[38;5;28;01mfor\u001b[39;00m i,ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chars_sorted)}\n\u001b[1;32m      3\u001b[0m char_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(chars_sorted)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'char_set' is not defined"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "text_encoded = np.array(\n",
    "    [char2int[ch] for ch in text],\n",
    "    dtype=np.int32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b47e9-3b28-4705-9b4e-63546262260c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcf77b5b-af1d-4eb5-9331-ec90b8678e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "text_chunks = [text_encoded[i:i+chunk_size] \n",
    "               for i in range(len(text_encoded)-chunk_size)]\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_chunks):\n",
    "        self.text_chunks = text_chunks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_chunk = torch.tensor(self.text_chunks[idx])\n",
    "        return text_chunk[:-1].long(), text_chunk[1:].long()\n",
    "\n",
    "seq_dataset = TextDataset(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc3396ec-f05c-438d-898a-f373da8f3fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "torch.manual_seed(0)\n",
    "seq_dl = DataLoader(seq_dataset, batch_size,\n",
    "                    shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "110b28ae-a59a-4c45-82ed-dd962100dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, device, vocab_size, embed_dim,\n",
    "                 rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim).to(device)\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, batch_first=True).to(device)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, vocab_size).to(device)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embedding(x).unsqueeze(1)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden, cell\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size).to(self.device)\n",
    "        cell = torch.zeros(1, batch_size, self.rnn_hidden_size).to(self.device)\n",
    "        return hidden, cell        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "61b9c4ac-dc69-44bb-8711-278c72ea348e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cea38324-8775-4f12-8563-3dda31feba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "torch.manual_seed(0)\n",
    "model = RNN(device, vocab_size, embed_dim, rnn_hidden_size)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3677458-7a70-49d2-b7f9-a1613994f9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500 Loss 1.4117\n",
      "Epoch 1000 Loss 1.3540\n",
      "Epoch 1500 Loss 1.3390\n",
      "Epoch 2000 Loss 1.1891\n",
      "Epoch 2500 Loss 1.2130\n",
      "Epoch 3000 Loss 1.1530\n",
      "Epoch 3500 Loss 1.1236\n",
      "Epoch 4000 Loss 1.1016\n",
      "Epoch 4500 Loss 1.0432\n",
      "Epoch 5000 Loss 1.1290\n",
      "Epoch 5500 Loss 1.0998\n",
      "Epoch 6000 Loss 1.0371\n",
      "Epoch 6500 Loss 1.0822\n",
      "Epoch 7000 Loss 1.0800\n",
      "Epoch 7500 Loss 1.0968\n",
      "Epoch 8000 Loss 1.0186\n",
      "Epoch 8500 Loss 1.0596\n",
      "Epoch 9000 Loss 1.0713\n",
      "Epoch 9500 Loss 1.0382\n",
      "Epoch 10000 Loss 1.0091\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "torch.manual_seed(0)\n",
    "model.train()\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    hidden, cell = model.init_hidden(batch_size)\n",
    "    seq_batch, target_batch = next(iter(seq_dl))\n",
    "    seq_batch = seq_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        pred, hidden, cell = model(seq_batch[:, c], hidden, cell)\n",
    "        loss += loss_fn(pred, target_batch[:, c])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item() / seq_length\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch {epoch} Loss {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6e6282b4-84b8-4222-a8fb-55f992befdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "def sample(model, starting_str,\n",
    "           len_generated_text=500,\n",
    "           scale_factor=1.0):\n",
    "    encoded_input = torch.tensor(\n",
    "        [char2int[ch] for ch in starting_str]\n",
    "    ).reshape(1, -1).to(device)\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.eval()\n",
    "    hidden, cell = model.init_hidden(1)\n",
    "    for c in range(len(starting_str) - 1):\n",
    "        _, hidde, cell = model(encoded_input[:, c], hidden, cell)\n",
    "\n",
    "    last_char = encoded_input[:, -1]\n",
    "    for i in range(len_generated_text):\n",
    "        logits, hidden, cell = model(\n",
    "            last_char.view(1), hidden, cell\n",
    "        )\n",
    "        logits = torch.squeeze(logits, 0)\n",
    "        scaled_logits = logits * scale_factor\n",
    "        m = Categorical(logits=scaled_logits)\n",
    "        last_char = m.sample().to(device)\n",
    "        generated_str += str(char_array[last_char])\n",
    "\n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab30e6b0-f7b4-4c7d-9857-3b4a4a77581f",
   "metadata": {},
   "source": [
    "#### Generated text, scale_factor = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fadc83bd-f028-4784-9d22-1cfd28808f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pencroft, cut in blown into the rocks, not even that metal\n",
      "place had been confident as a communication with, and always after having been being once and, for they had been, were well, the former castaways, covered weapons with yourself.\n",
      "\n",
      "“I would still\n",
      "struggle it; Herbert separated some time.”\n",
      "\n",
      "“Then pipe.”\n",
      "\n",
      "“I am she we enable that,” said Cyrus Harding; “for no island could not be thrown up, and if they would construct a prey when the incidents were now wing morth?\n",
      "\n",
      "What a more effect.\n",
      "\n",
      "During\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "print(sample(model, starting_str=' ', scale_factor=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6602c180-e16d-4940-b723-7a9df795a5c7",
   "metadata": {},
   "source": [
    "#### Generated text, scale_factor = 0.5 (more random generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2142ed82-ad70-40c2-9b5a-27352d38f9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fadaine.”\n",
      " Dail It did noburans ty bocomowary, laited necessity. Matters assirved us-’at’-bank; no ized unfoor rate. At\n",
      "their, beyodes, where dressark,”s endshile, more saltic”! adefarcounded?\n",
      "\n",
      "Ayrton-foring Gidnoinhestoms as the\n",
      "breezing. Twey fast?\n",
      "Hirtleith thus those vauled betwein it.\n",
      "Outsiw’ timped itself.\n",
      "\n",
      "“Oh igningbouildining-machings,” he said,-whomoutiously this heat, burry quarse,’s being quice hed. Their wholb\n",
      "tight anticallant civicing hoist, eighth fusgeh.\n",
      "Neb,\n",
      "of jessp coat dante\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, starting_str=' ', scale_factor=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf65fdb-ac47-4d76-8551-340a4d422aba",
   "metadata": {},
   "source": [
    "#### Generated text, scale_factor = 3.0 (more deterministic generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "37c4d67e-e359-4308-aec2-f29630977383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the reporter.\n",
      "\n",
      "“No, my boy,” replied the reporter.\n",
      "\n",
      "“No, Pencroft, that is to say, our first cavern with the interior of the island with a good castaway.”\n",
      "\n",
      "“But what are you mean to be an account of the productions of the mountain,” said the reporter, “but we cannot see if it is a man to find himself out of the country?” asked Herbert, “the river will be no doubt that the interior of the convicts had been carried to the corral. The contrary, the colonists were not more than the colonists, who wa\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, starting_str=' ', scale_factor=3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "00b27f62-b6be-4783-bbd0-e362acb05ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'char_level_lang_modeling_RNN.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
